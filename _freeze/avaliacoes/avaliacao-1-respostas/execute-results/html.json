{
  "hash": "5ab2124120440ca472ecc393587c04fc",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Avaliação 1 – Introdução à Inferência Bayesiana\"\nsubtitle: \"5290 - PROBABILIDADE E ESTATÍSTICA\"\ndescription: \"Curso de Bacharelado Interdisciplinar em Ciência e Tecnologia do Mar - BICT Mar\"\nauthor: \"Fabio Cop Ferreira\"\n\nformat:\n  html:\n    number-sections: true\n    number-depth: 3\n    include-in-header: \n      text: |\n        <style>\n        h2 {\n          font-size: 1.1rem !important; /* h2 menor */\n        }\n        h3 {\n          font-size: 1rem !important; /* h3 menor */\n        }\n        </style>\n\n---\n\n\n---\n\n<div style=\"text-align: center; font-weight: bold; color: red\">\nRESPOSTAS DAS QUESTÕES\n</div>\n\n---\n\n## Parte A – Questões conceituais (2,0 pontos)\n\n### (0,5 ponto) Em uma análise bayesiana, a *verossimilhança* de uma hipótese:\n\n**Resposta:** <span style=\"color: red\">B) Mede a proporção relativa de modos pelos quais a hipótese pode produzir os dados observados.</span>\n\n### (0,5 ponto) Ao assumir uma distribuição *a priori* uniforme sobre cinco hipóteses discretas, o peso inicial atribuído a cada hipótese é:\n\n**Resposta:** <span style=\"color: red\">B) 0,20</span>\n\n### (0,5 ponto) Indique a alternativa que **não** altera a distribuição *a posteriori*:\n\n**Resposta:** <span style=\"color: red\">D) Multiplicar todas as probabilidades posteriores por uma constante comum.</span>\n\n### (0,5 ponto) Quando a distribuição *a priori* é **informativa** e favorece valores altos de um parâmetro, o impacto esperado sobre a distribuição *a posteriori* é:\n\n**Resposta:** <span style=\"color: red\">B) Deslocá‑la na direção dos valores altos, a depender dos dados.</span>\n\n---\n\n::: {#6c9ddf3f .cell execution_count=1}\n``` {.python .cell-code}\nfrom scipy.stats import binom\nimport numpy as np\n\ny = 2\nn = 3\np = np.arange(0,5)/4\npriori = 1/len(p)\n\nL = binom.pmf(y, n, p)\nPost = L * priori / np.sum(L * priori)\nL_round = np.round(L,3).tolist()\nPost_round = np.round(Post,3).tolist()\n\nH_selecionado = int(np.argmax(Post) + 1)\n```\n:::\n\n\n## Parte B – Problemas quantitativos (8,0 pontos)\n\n| Hipótese | Composição | $n$ | $\\mathcal{L}$ | Probabilidade *a posteriori* |\n|:--------:|:----------:|:---:|:-------------:|:----------------------------:|\n| $H_1$    | ⚪⚪⚪⚪      | <span style=\"color: red\">$0 \\times 4 \\times 0 = 0$</span>   | <span style=\"color: red\">0.0</span>   | <span style=\"color: red\">0.0</span>  |\n| $H_2$    | ⚪⚪⚪🔵      | <span style=\"color: red\">$1 \\times 3 \\times 1 = 3$</span>   | <span style=\"color: red\">0.141</span>   | <span style=\"color: red\">0.15</span>  |\n| $H_3$    | ⚪⚪🔵🔵      | <span style=\"color: red\">$2 \\times 2 \\times 2 = 8$</span>   | <span style=\"color: red\">0.375</span>   | <span style=\"color: red\">0.4</span>  |\n| $H_4$    | ⚪🔵🔵🔵      | <span style=\"color: red\">$3 \\times 1 \\times 3 = 9$</span>   | <span style=\"color: red\">0.422</span>   | <span style=\"color: red\">0.45</span>  |\n| $H_5$    | 🔵🔵🔵🔵      | <span style=\"color: red\">$4 \\times 0 \\times 4 = 0$</span>   | <span style=\"color: red\">0.0</span>   | <span style=\"color: red\">0.0</span>  |\n\n### Hipótese mais plausível (priori uniforme):\n\n**Resposta:** <span style=\"color: red\">E) $H_{4}$</span>\n\n---\n\n### Probabilidade *a posteriori* com *a priori* informativa:\n\n::: {#fbc97f3e .cell execution_count=2}\n``` {.python .cell-code}\nfrom scipy.stats import binom\nimport numpy as np\n\ny = 2\nn = 3\np = np.arange(0,5)/4\npriori_info = np.array([0.05, 0.1, 0.6, 0.15, 0.1])\n\nL_info = binom.pmf(y, n, p)\nPost_info = L_info * priori_info / np.sum(L_info * priori_info)\nL_info_round = np.round(L_info,3).tolist()\nPost_info_round = np.round(Post_info,3).tolist()\n\nH_info_selecionado = int(np.argmax(Post_info) + 1)\n```\n:::\n\n\n| Hipótese | Composição | Probabilidade *a priori* | Probabilidade *a posteriori* |\n|:--------:|:----------:|:------------------------:|:----------------------------:|\n| $H_1$    | ⚪⚪⚪⚪      | 0.05                     | <span style=\"color: red\">0.0</span>  |\n| $H_2$    | ⚪⚪⚪🔵      | 0.10                     | <span style=\"color: red\">0.047</span>  |\n| $H_3$    | ⚪⚪🔵🔵      | 0.60                     | <span style=\"color: red\">0.744</span>  |\n| $H_4$    | ⚪🔵🔵🔵      | 0.15                     | <span style=\"color: red\">0.209</span>  |\n| $H_5$    | 🔵🔵🔵🔵      | 0.10                     | <span style=\"color: red\">0.0</span>  |\n\n### Hipótese mais plausível (priori informativa):\n\n**Resposta:** <span style=\"color: red\">E) $H_{3}$</span>\n\n---\n\n## Parte C – Problemas de interpretação e uso (2,0 pontos)\n\n::: {#cb9e15d9 .cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nfrom scipy.stats import beta\n\n# Definições dos parâmetros dos cenários\nalpha_prior = np.array([1, 9, 1, 9])\nbeta_prior =  np.array([1, 4, 1, 4])\ny =           np.array([3, 3, 30, 30])\nn =           np.array([4, 4, 40, 40])\n\n# Parâmetros da posteriori\nalpha_post = alpha_prior + y\nbeta_post = beta_prior + (n - y)\n\n# Intervalo desejado\nlower, upper = 0.65, 0.75\n\n# Probabilidade acumulada entre os limites\ncdf_upper = beta.cdf(upper, alpha_post, beta_post)\ncdf_lower = beta.cdf(lower, alpha_post, beta_post)\nposterior_probs = cdf_upper - cdf_lower\n\nposterior_probs_round = np.round(posterior_probs,3).tolist()\n```\n:::\n\n\n### (0,5 ponto) $n = 4$, $y = 3$, *a priori* $Beta(1, 1)$  \n**Resposta:** <span style=\"color: red\">0.204</span>\n\n### (0,5 ponto) $n = 4$, $y = 3$, *a priori* $Beta(9, 4)$  \n**Resposta:** <span style=\"color: red\">0.341</span>\n\n### (0,5 ponto) $n = 40$, $y = 30$, *a priori* $Beta(1, 1)$  \n**Resposta:** <span style=\"color: red\">0.446</span>\n\n### (0,5 ponto) $n = 40$, $y = 30$, *a priori* $Beta(9, 4)$  \n**Resposta:** <span style=\"color: red\">0.49</span>\n\n---\n\n",
    "supporting": [
      "avaliacao-1-respostas_files"
    ],
    "filters": [],
    "includes": {}
  }
}
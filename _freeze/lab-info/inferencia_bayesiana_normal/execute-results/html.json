{
  "hash": "b1eb9c4d4b4e64a91d3b6513150cbbc0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Semana 6: Distribuição Normal e Inferência Bayesiana com PyMC\"\nsubtitle: \"Modelando Dados Contínuos\"\ndescription: \"Introdução à modelagem Bayesiana de dados contínuos com a Distribuição Normal usando PyMC, incluindo escolha de priores, checagens preditivas e interpretação da posteriori.\"\nformat: html\n---\n\n\n### Notebook Semana 6: Distribuição Normal e Inferência Bayesiana com PyMC\n\n**Objetivos de Aprendizagem:**\n\nAo final desta semana, você deverá ser capaz de:\n\n*   Apresentar e entender a Distribuição Normal de forma intuitiva.\n*   Simular dados a partir de distribuições normais usando `scipy`.\n*   Utilizar seu conhecimento subjetivo para propor e visualizar distribuições a priori preditivas para parâmetros de um modelo Normal (como altura humana).\n*   Definir e ajustar um modelo Normal Bayesiano no PyMC.\n*   Extrair e interpretar as distribuições a posteriori dos parâmetros do modelo usando `arviz`.\n*   Gerar e avaliar checks preditivos a posteriori para verificar o ajuste do modelo.\n\nNesta semana, continuaremos a explorar a inferência Bayesiana, movendo-nos para a modelagem de dados contínuos usando a Distribuição Normal. Nosso foco será desenvolver a intuição sobre como escolher distribuições a priori e como o PyMC nos ajuda a combinar essas crenças com dados observados para obter distribuições a posteriori.\n\nVamos utilizar um exemplo prático: modelar a altura humana.\n\n::: {#9df255df .cell execution_count=1}\n``` {.python .cell-code}\n# Importando bibliotecas necessárias\nimport pymc as pm\nimport arviz as az\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport pandas as pd # Para lidar com dados potenciais\n\n# Configurações para plots\nplt.style.use('seaborn-v0_8-darkgrid')\naz.style.use(\"arviz-darkgrid\")\n```\n:::\n\n\n#### Parte 1: Explorando a Distribuição Normal\n\nA Distribuição Normal, frequentemente chamada de \"curva de sino\" ou Gaussiana, é fundamental em estatística. Ela é caracterizada por dois parâmetros: a média ($\\mu$) e o desvio padrão ($\\sigma$). A média determina o centro da distribuição, enquanto o desvio padrão determina sua dispersão ou \"largura\". Muitos fenômenos naturais, como altura humana, tendem a seguir aproximadamente essa distribuição.\n\n**A ideia intuitiva:** Pense na altura de adultos. Há um valor central (a média) em torno do qual a maioria das alturas se agrupa. Há também uma variação: algumas pessoas são mais altas, outras mais baixas, e o desvio padrão nos diz o quão espalhadas essas alturas tendem a ser em relação à média.\n\nVamos visualizar como a densidade da Distribuição Normal muda com diferentes valores para $\\mu$ e $\\sigma$.\n\n::: {#ad34220d .cell execution_count=2}\n``` {.python .cell-code}\n# Visualizando densidades da Distribuição Normal\nmu_values = [170, 175, 180] # em cm (Exemplo)\nsigma_values = [5, 7, 9]   # em cm (Exemplo)\ncolors = ['blue', 'green', 'red']\n\nx = np.linspace(140, 210, 1000) # Faixa de alturas para plotar\n\nplt.figure(figsize=(10, 6))\n\nfor mu, sigma, color in zip(mu_values, sigma_values, colors):\n    pdf = stats.norm.pdf(x, loc=mu, scale=sigma)\n    plt.plot(x, pdf, label=f'μ={mu}, σ={sigma}', color=color, lw=2)\n\nplt.title('Densidades da Distribuição Normal', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Densidade de Probabilidade', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-3-output-1.png){width=1011 height=611}\n:::\n:::\n\n\nPodemos também gerar *amostras* de uma distribuição Normal. Isso simula o processo de \"sortear\" alturas de uma população que segue essa distribuição.\n\n::: {#dbd55f97 .cell execution_count=3}\n``` {.python .cell-code}\n# Gerando amostras de uma Distribuição Normal\nmu_exemplo = 175 # cm\nsigma_exemplo = 7 # cm\nnum_amostras = 500\n\namostras_altura = stats.norm.rvs(loc=mu_exemplo, scale=sigma_exemplo, size=num_amostras)\n\nplt.figure(figsize=(10, 6))\nplt.hist(amostras_altura, bins=30, density=True, alpha=0.7, color='purple', label='Amostras Geradas')\n# Recalculando o grid x para o plot da densidade teórica\nx_dens = np.linspace(amostras_altura.min(), amostras_altura.max(), 500)\nplt.plot(x_dens, stats.norm.pdf(x_dens, loc=mu_exemplo, scale=sigma_exemplo), color='orange', linewidth=2.5, label='Densidade Teórica')\nplt.title(f'Histograma de {num_amostras} Amostras e Densidade Normal (μ={mu_exemplo}, σ={sigma_exemplo})', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Densidade / Frequência Normalizada', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-4-output-1.png){width=1011 height=611}\n:::\n:::\n\n\nObserve como o histograma das amostras geradas se aproxima da curva de densidade teórica, especialmente com um número maior de amostras.\n\n#### Parte 2: Intuição da Priori Preditiva e Checks\n\nEm inferência Bayesiana, começamos com crenças sobre os parâmetros (a priori) e as atualizamos com dados (a posteriori). Para a altura humana, já temos uma intuição! Sabemos que a média da altura de adultos não é 50 cm nem 300 cm. O desvio padrão também não é 1 cm (pois haveria muito pouca variação) nem 50 cm (pois a variação seria enorme).\n\n**Atividade para você (Estudante):**\n\nBaseado na sua intuição sobre la altura de adultos, **proponha valores razoáveis** para a média ($\\mu$) e o desvio padrão ($\\sigma$). Escolha distribuições a priori simples para representá-los, por exemplo:\n*   Para a média ($\\mu$): Uma distribuição Normal centrada em um valor que você acha razoável, com um desvio padrão que reflete sua incerteza sobre esse valor médio. Ex: $\\mu \\sim \\text{Normal}(\\text{sua média intuição}, \\text{sua incerteza})$.\n*   Para o desvio padrão ($\\sigma$): Como $\\sigma$ deve ser positivo, podemos usar distribuições como a Uniforme ou Half-Cauchy (meia Cauchy). Ex: $\\sigma \\sim \\text{Uniform}(0, \\text{valor máximo razoável})$ ou $\\sigma \\sim \\text{HalfCauchy}(\\text{beta})$.\n\n**Escolha seus próprios parâmetros para estas distribuições a priori:**\n\n*   Minha Priori para $\\mu$: $\\mu \\sim \\text{Normal}(\\text{loc=____}, \\text{scale=____})$\n*   Minha Priori para $\\sigma$: $\\sigma \\sim \\text{Uniform}(\\text{low=____}, \\text{high=____})$ (ou outra, se preferir)\n\nAgora, visualize *suas escolhas* de distribuições a priori:\n\n::: {#fb21ecb4 .cell execution_count=4}\n``` {.python .cell-code}\n# ----- Substitua pelos SEUS valores escolhidos! -----\nsua_mu_priori_loc = 175  # Ex: Sua intuição para a média\nsua_mu_priori_scale = 10 # Ex: Sua incerteza sobre a média\n\nsua_sigma_priori_low = 1   # Ex: Mínimo razoável para sigma (maior que 0)\nsua_sigma_priori_high = 20 # Ex: Máximo razoável para sigma (se usar Uniforme)\n# Se usar outra priori para sigma (ex: HalfCauchy), ajuste o código de visualização abaixo\n# Ex: sua_sigma_priori_beta = 10 (para HalfCauchy)\n# ----------------------------------------------------\n\n# Visualizando SUAS distribuições a priori\nx_mu_priori = np.linspace(sua_mu_priori_loc - 4*sua_mu_priori_scale,\n                          sua_mu_priori_loc + 4*sua_mu_priori_scale, 500)\nmu_priori_pdf = stats.norm.pdf(x_mu_priori, loc=sua_mu_priori_loc, scale=sua_mu_priori_scale)\n\n# Para sigma, precisamos de um grid de valores positivos\nsigma_grid = np.linspace(0.1, sua_sigma_priori_high + 10, 1000) # Ajuste a faixa se necessário\n\n# Exemplo com Uniforme para sigma\nsigma_priori_pdf = stats.uniform.pdf(sigma_grid, loc=sua_sigma_priori_low,\n                                     scale=sua_sigma_priori_high - sua_sigma_priori_low)\n\n# # Exemplo Alternativo com HalfCauchy para sigma (descomente se usar)\n# sua_sigma_priori_beta = 10 # Defina o parâmetro beta\n# sigma_priori_pdf = stats.halfcauchy.pdf(sigma_grid, scale=sua_sigma_priori_beta)\n# sua_sigma_priori_low = 0 # HalfCauchy começa em 0\n\n\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(x_mu_priori, mu_priori_pdf, color='crimson', lw=2)\nplt.title(f'Sua Priori para μ: Normal({sua_mu_priori_loc}, {sua_mu_priori_scale})', fontsize=13)\nplt.xlabel('μ (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\n\nplt.subplot(1, 2, 2)\nplt.plot(sigma_grid, sigma_priori_pdf, color='darkblue', lw=2)\n# Ajuste o título conforme a distribuição escolhida\nplt.title(f'Sua Priori para σ: Uniforme({sua_sigma_priori_low}, {sua_sigma_priori_high})', fontsize=13)\n# plt.title(f'Sua Priori para σ: HalfCauchy(beta={sua_sigma_priori_beta})', fontsize=13) # Alternativa\nplt.xlabel('σ (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\n# Defina limites para melhor visualização da priori de sigma\nplt.xlim(0, sua_sigma_priori_high + 5) # Ajuste se necessário\nif sua_sigma_priori_low > 0: # Linha vertical no limite inferior se > 0\n     plt.axvline(sua_sigma_priori_low, color='grey', linestyle=':', lw=1.5)\nif sua_sigma_priori_high < np.inf: # Linha vertical no limite superior se finito\n     plt.axvline(sua_sigma_priori_high, color='grey', linestyle=':', lw=1.5)\nplt.grid(True, linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_44037/4085594884.py:53: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-5-output-2.png){width=1390 height=592}\n:::\n:::\n\n\n**Consolidando Priores (Feito pelo Professor):**\n\nCom base nas sugestões de toda a turma, o professor consolidará um conjunto \"compartilhado\" de distribuições a priori para $\\mu$ e $\\sigma$. Para este notebook, usaremos um exemplo de priores compartilhadas:\n\n*   Priori Compartilhada para $\\mu$: $\\mu \\sim \\text{Normal}(175, 10)$\n*   Priori Compartilhada para $\\sigma$: $\\sigma \\sim \\text{HalfCauchy}(10)$ (Uma escolha comum para desvios padrão positivos, pois permite valores maiores mas com probabilidade decrescente)\n\n**Checagem Priori Preditiva:**\n\nUm passo crucial no fluxo de trabalho Bayesiano é a checagem priori preditiva. Antes mesmo de olhar os dados, podemos simular *possíveis conjuntos de dados* que poderiam ser gerados apenas com base em nossas distribuições a priori. Isso nos ajuda a ver se nossas crenças iniciais (as priores) levam a expectativas razoáveis para os dados que esperamos observar. Se a simulação priori preditiva produzir alturas absurdas (ex: muitas alturas negativas, ou a maioria das alturas acima de 300 cm), isso indica que nossas priores não são adequadas e precisam ser revisadas.\n\nVamos usar o PyMC para definir o modelo apenas com as priores e gerar amostras preditivas a priori:\n\n::: {#4ffe8ffa .cell execution_count=5}\n``` {.python .cell-code}\n# Definindo o modelo APENAS com as priores compartilhadas\nwith pm.Model() as prior_predictive_model:\n    # Priores compartilhadas (exemplo)\n    mu = pm.Normal(\"mu\", mu=175, sigma=10) # Priori para a média\n    sigma = pm.HalfCauchy(\"sigma\", beta=0.05)# Priori para o desvio padrão (deve ser > 0)\n\n    # O likelihood APENAS define a forma da distribuição que esperamos para os dados\n    # Não passamos dados 'observed' aqui para gerar a PRIORI preditiva\n    # O parâmetro 'shape' é opcional aqui, mas útil se quiséssemos simular múltiplos pontos por amostra priori\n    y_pred = pm.Normal(\"y_pred\", mu=mu, sigma=sigma) # Gerará uma amostra por combinação de mu/sigma\n\n    # Gerando amostras da PRIORI preditiva\n    prior_predictive_samples = pm.sample_prior_predictive(samples=500, random_seed=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling: [mu, sigma, y_pred]\n```\n:::\n:::\n\n\nAgora, vamos visualizar a distribuição dessas amostras preditivas a priori:\n\n::: {#ebe89b7b .cell execution_count=6}\n``` {.python .cell-code}\n# Visualizando a checagem priori preditiva\nprior_pred_data = prior_predictive_samples.prior[\"y_pred\"].values.flatten()\n\nplt.figure(figsize=(10, 6))\nplt.hist(prior_pred_data, bins=50, density=True, alpha=0.75, color='skyblue')\nplt.title('Checagem Priori Preditiva para Altura', fontsize=14)\nplt.xlabel('Altura Simulada (cm) [Baseada Apenas nas Priores]', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\nprint(f\"Range das alturas simuladas a priori: {prior_pred_data.min():.1f} cm a {prior_pred_data.max():.1f} cm\")\n```\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-7-output-1.png){width=1011 height=611}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRange das alturas simuladas a priori: 139.4 cm a 206.7 cm\n```\n:::\n:::\n\n\n> **Discussão:** Olhe para este histograma. As alturas simuladas parecem razoáveis para alturas de adultos? A distribuição faz sentido dada a sua intuição? Se sim, suas priores iniciais eram sensatas. Se não, você consideraria ajustar suas priores (ex: tornar a priori de $\\sigma$ mais restrita se a dispersão for muito grande, ou ajustar a localização/escala da priori de $\\mu$).\n\n#### Parte 3: Inferência Posterior e Posterior Predictive Checks\n\nAgora é hora de incorporar dados reais. Vamos usar um conjunto de dados de exemplo (simulado para este notebook, mas pode ser substituído por dados reais da sua turma ou de outra fonte) e realizar a inferência Bayesiana completa.\n\n::: {#ce4e66b4 .cell execution_count=7}\n``` {.python .cell-code}\n# Gerando um conjunto de dados de exemplo (substituir por dados reais se disponíveis)\nnp.random.seed(123) # Para reprodutibilidade\nmedia_real_simulada = 172\ndp_real_simulado = 8\nn_observacoes = 100\nalturas_observadas = stats.norm.rvs(loc=media_real_simulada, scale=dp_real_simulado, size=n_observacoes)\n\nprint(f\"Dados observados (primeiros 10): {alturas_observadas[:10]}\")\nprint(f\"\\nMédia amostral: {np.mean(alturas_observadas):.2f} cm\")\nprint(f\"Desvio padrão amostral: {np.std(alturas_observadas):.2f} cm\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(alturas_observadas, bins=15, density=True, alpha=0.8, color='gray', label='Dados Observados')\nplt.title(f'Histograma das {n_observacoes} Alturas Observadas', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDados observados (primeiros 10): [163.31495517 179.97876357 174.26382798 159.94964229 167.37119798\n 185.2114923  152.58656605 168.56869897 182.12749007 165.06607678]\n\nMédia amostral: 172.22 cm\nDesvio padrão amostral: 9.03 cm\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-8-output-2.png){width=1011 height=611}\n:::\n:::\n\n\nAgora, definimos o modelo Bayesiano COMPLETO no PyMC. Isso inclui as distribuições a priori (compartilhadas) e o likelihood, que conecta os parâmetros aos dados *observados*.\n\n::: {#9bc3a2c5 .cell execution_count=8}\n``` {.python .cell-code}\n# Definindo o modelo Bayesiano COMPLETO no PyMC\nwith pm.Model() as normal_model:\n    # Priores (usamos as priores compartilhadas da parte anterior)\n    mu = pm.Normal(\"mu\", mu=175, sigma=10)       # Priori para a média\n    sigma = pm.HalfCauchy(\"sigma\", beta=0.1)    # Priori para o desvio padrão\n\n    # Likelihood: Distribuição dos dados OBSERVADOS, condicionada pelos parâmetros\n    # Aqui, informamos ao modelo quais dados foram observados usando o argumento 'observed'\n    likelihood = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=alturas_observadas)\n\n    # Inferência: Amostragem da distribuição a posteriori usando MCMC\n    # O PyMC usa o sampler NUTS (No-U-Turn Sampler) por padrão\n    # Ele explora o espaço de parâmetros para encontrar as regiões de alta probabilidade a posteriori\n    # draws: número de amostras a guardar por cadeia\n    # tune: número de passos de aquecimento (tuning) para o sampler convergir (descartados)\n    # cores: número de núcleos da CPU para rodar cadeias em paralelo (acelera)\n    # return_inferencedata=True: retorna um objeto ArviZ InferenceData, que é conveniente\n    trace = pm.sample(draws=2000, tune=1000, cores=4, return_inferencedata=True, random_seed=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu, sigma]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/cop/Documents/Material_Didatico/uc-probabilidade-estatistica/.venv/lib/python3.10/site-packages/rich/live.py:\n231: UserWarning: install \"ipywidgets\" for Jupyter support\n  warnings.warn('install \"ipywidgets\" for Jupyter support')\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 1 seconds.\n```\n:::\n:::\n\n\nO `pm.sample()` executa o algoritmo MCMC. Ele gera *amostras* da distribuição a posteriori conjunta de $\\mu$ e $\\sigma$. O resultado `trace` (um objeto InferenceData do ArviZ) contém essas amostras.\n\n**Inspeção e Interpretação da Posteriori:**\n\nAs amostras na `trace` representam nosso conhecimento atualizado sobre $\\mu$ e $\\sigma$ APÓS vermos os dados. Podemos resumir e visualizar essas amostras para entender a distribuição a posteriori.\n\n::: {#44ece8f2 .cell execution_count=9}\n``` {.python .cell-code}\n# Resumo da distribuição a posteriori usando ArviZ\n# 'var_names' especifica quais variáveis queremos sumarizar\n# hdi_prob: probabilidade coberta pelo Intervalo de Maior Densidade (HDI - Highest Density Interval)\nsummary_stats = az.summary(trace, var_names=[\"mu\", \"sigma\"], hdi_prob=0.94, kind='stats')\n\nprint(\"Resumo das Estatísticas Posteriores:\")\nprint(summary_stats)\n\n# r_hat: Deve ser próximo de 1 (< 1.01 é bom), indica convergência entre as cadeias MCMC\n# ess_bulk / ess_tail: Effective Sample Size (tamanho efetivo da amostra), indica eficiência da amostragem\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResumo das Estatísticas Posteriores:\n          mean     sd   hdi_3%  hdi_97%\nmu     172.242  0.888  170.545  173.887\nsigma    9.094  0.656    7.872   10.313\n```\n:::\n:::\n\n\nO resumo mostra a média posterior, desvio padrão posterior e um Intervalo de Alta Densidade (HDI) de 94% para cada parâmetro. O HDI é um intervalo de credibilidade Bayesiano que contém 94% da massa de probabilidade posterior, incluindo os valores mais prováveis.\n\nVisualizações são essenciais para entender a posteriori:\n\n::: {#e521f5df .cell execution_count=10}\n``` {.python .cell-code}\n# Visualização da amostragem MCMC (Trace Plot) e da densidade a posteriori marginal\n# O trace plot (gráfico da esquerda) mostra a trajetória do sampler ao longo das iterações para cada cadeia.\n#   Idealmente, parece um \"ruído branco estacionário\", sem tendências ou padrões óbvios.\n# O histograma ou KDE (gráfico da direita) mostra a distribuição marginal a posteriori estimada de cada parâmetro.\naz.plot_trace(trace, var_names=[\"mu\", \"sigma\"])\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_44037/2558706149.py:6: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-11-output-2.png){width=1187 height=388}\n:::\n:::\n\n\n::: {#ce987750 .cell execution_count=11}\n``` {.python .cell-code}\n# Visualização das densidades a posteriori marginais com média, mediana e HDI\n# Este plot foca na distribuição de probabilidade de cada parâmetro INDIVIDUALMENTE,\n# após levarmos em conta os dados e as priores.\naz.plot_posterior(trace, var_names=[\"mu\", \"sigma\"], hdi_prob=0.94)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-12-output-1.png){width=1667 height=563}\n:::\n:::\n\n\n> **Discussão:**\n> *   Compare as distribuições a posteriori (visualizadas acima) com suas distribuições a priori iniciais (que você visualizou na Parte 2). Como os dados *atualizaram* suas crenças? Os centros das distribuições mudaram? Elas ficaram mais \"estreitas\" (menor incerteza)?\n> *   Qual é a média posterior estimada para $\\mu$? E para $\\sigma$? Como esses valores se comparam com a média (`171.66`) e o desvio padrão (`7.90`) calculados diretamente a partir dos dados observados (estimativas frequentistas)? Geralmente são próximos, mas não idênticos devido à influência (mesmo que pequena) das priores.\n> *   Interprete o intervalo HDI de 94% para $\\mu$ e $\\sigma$. Por exemplo, para $\\mu$, o intervalo é `[170.09, 173.23]`. Isso significa que, após observar os dados e considerando nossas priores, temos 94% de certeza (probabilidade Bayesiana) de que a verdadeira média populacional $\\mu$ da altura está entre 170.09 cm e 173.23 cm. Faça uma interpretação similar para $\\sigma$.\n\n**Checagem Posterior Preditiva:**\n\nAssim como fizemos a checagem priori preditiva, podemos fazer uma checagem *posterior* preditiva. Desta vez, geramos dados simulados a partir do modelo USANDO as amostras da *distribuição a posteriori* dos parâmetros ($\\mu$ e $\\sigma$). Cada conjunto de dados simulado usa um par $(\\mu, \\sigma)$ sorteado da posteriori. Isso nos diz que tipos de dados o modelo espera gerar agora que ele aprendeu com os dados observados. É uma ótima maneira de avaliar o **ajuste do modelo (model fit)**. Se os dados simulados a posteriori forem muito diferentes dos dados observados, o modelo pode não estar capturando bem as características dos dados reais.\n\n::: {#ce9f9574 .cell execution_count=12}\n``` {.python .cell-code}\n# Gerando amostras da POSTERIOR preditiva\n# Usamos o 'normal_model' (que contém o likelihood e as priores)\n# e o 'trace' (que contém as amostras da posteriori dos parâmetros)\nwith normal_model:\n    posterior_predictive_samples = pm.sample_posterior_predictive(trace, var_names=[\"likelihood\", \"mu\", \"sigma\"], random_seed=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling: [likelihood, mu, sigma]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/cop/Documents/Material_Didatico/uc-probabilidade-estatistica/.venv/lib/python3.10/site-packages/rich/live.py:\n231: UserWarning: install \"ipywidgets\" for Jupyter support\n  warnings.warn('install \"ipywidgets\" for Jupyter support')\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n:::\n\n\n::: {#041bb234 .cell execution_count=13}\n``` {.python .cell-code}\n# Visualizando a checagem posterior preditiva com ArviZ\n# Comparamos a distribuição dos dados observados (y) com as distribuições\n# de múltiplos conjuntos de dados simulados a partir da posteriori (y_pred).\n# 'kind='hist'' plota o histograma dos dados observados (azul escuro) e sobrepõe\n# histogramas de vários conjuntos de dados simulados da posteriori (azul claro).\n# Idealmente, o histograma observado deve se parecer com os simulados.\naz.plot_ppc(posterior_predictive_samples, num_pp_samples=100) # num_pp_samples controla quantos datasets simulados mostrar\nplt.title('Checagem Posterior Preditiva (PPC)', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Contagem (ou Densidade)', fontsize=12)\nplt.legend(fontsize=10)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](inferencia_bayesiana_normal_files/figure-html/cell-14-output-1.png){width=731 height=491}\n:::\n:::\n\n\n> **Discussão:**\n> *   Observe a figura `plot_ppc` acima. Quão bem o histograma dos dados observados (geralmente em azul mais escuro ou preto) se alinha com os histogramas dos dados simulados a posteriori (linhas ou área em azul claro)? Eles cobrem o mesmo intervalo? Têm formas semelhantes?\n> *   O modelo Normal parece adequado para descrever a distribuição das alturas neste conjunto de dados? Se o histograma observado fosse muito diferente (ex: bimodal, muito assimétrico) dos simulados, isso indicaria que o modelo Normal talvez não seja a melhor escolha para estes dados específicos. Neste caso, o ajuste parece razoável.\n\n#### Conclusão\n\nNesta semana, exploramos a Distribuição Normal e aprendemos como aplicá-la em um fluxo de trabalho de inferência Bayesiana usando o PyMC. Vimos como começar com intuições (priores), checar essas intuições (cheque priori preditivo), combinar priores com dados (inferência posterior via MCMC no PyMC) e avaliar o ajuste do modelo resultante (cheque posterior preditivo). Você agora tem as ferramentas básicas para modelar dados contínuos com incerteza usando a abordagem Bayesiana no Python!\n\n",
    "supporting": [
      "inferencia_bayesiana_normal_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}
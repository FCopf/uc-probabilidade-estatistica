{
  "hash": "3de9ab611a868d984ed99385cc9a9e96",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Distribuição Normal e Inferência Bayesiana\"\nsubtitle: \"Modelando Dados Contínuos no PyMC - distribições a posteriori\"\ndescription: \"Introdução à modelagem Bayesiana de dados contínuos no PyMC e estimativa da posteriori.\"\nformat: html\n---\n\n\n\n\n\nNesta semana, iremos a explorar a inferência Bayesiana, focando na modelagem de dados contínuos usando a Distribuição Normal. Nosso foco será desenvolver a intuição sobre como escolher distribuições a *priori* e como o PyMC nos ajuda a combinar essas crenças com dados observados para obter distribuições a *posteriori*. Para isdso usaremos um exemplo sobre a distribuição de altura em adultos.\n\n::: {.callout-important title=\"Objetivos de Aprendizagem\"}\nAo final desta aula, você deverá ser capaz de:\n\n*   Apresentar e entender a Distribuição Normal de forma intuitiva.\n*   Simular dados a partir de distribuições normais usando `scipy`.\n*   Utilizar seu conhecimento subjetivo para propor e visualizar distribuições a *priori* preditivas para parâmetros de um modelo Normal (como altura humana).\n*   Definir e ajustar um modelo Normal Bayesiano no PyMC.\n*   Extrair e interpretar as distribuições a *posteriori* dos parâmetros do modelo usando `arviz`.\n*   Gerar e avaliar checks preditivos a *posteriori* para verificar o ajuste do modelo.\n\n:::\n\n::: {#8b5868ea .cell execution_count=1}\n``` {.python .cell-code}\n# Importando bibliotecas necessárias\nimport pymc as pm\nimport arviz as az\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Configurações para plots\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (9, 6)\naz.style.use(\"arviz-darkgrid\")\n```\n:::\n\n\n## Inferência Posterior e Posterior Predictive Checks\n\nAgora é hora de incorporar dados reais. Vamos usar um conjunto de dados de exemplo (simulado para este notebook, mas pode ser substituído por dados reais da sua turma ou de outra fonte) e realizar a inferência Bayesiana completa.\n\n::: {#cce3c768 .cell execution_count=2}\n``` {.python .cell-code}\n# Gerando um conjunto de dados de exemplo (substituir por dados reais se disponíveis)\nnp.random.seed(123) # Para reprodutibilidade\nmedia_real_simulada = 172\ndp_real_simulado = 8\nn_observacoes = 100\nalturas_observadas = stats.norm.rvs(loc=media_real_simulada, scale=dp_real_simulado, size=n_observacoes)\n\nprint(f\"Dados observados (primeiros 10): {alturas_observadas[:10]}\")\nprint(f\"\\nMédia amostral: {np.mean(alturas_observadas):.2f} cm\")\nprint(f\"Desvio padrão amostral: {np.std(alturas_observadas):.2f} cm\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(alturas_observadas, bins=15, density=True, alpha=0.8, color='gray', label='Dados Observados')\nplt.title(f'Histograma das {n_observacoes} Alturas Observadas', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDados observados (primeiros 10): [163.31495517 179.97876357 174.26382798 159.94964229 167.37119798\n 185.2114923  152.58656605 168.56869897 182.12749007 165.06607678]\n\nMédia amostral: 172.22 cm\nDesvio padrão amostral: 9.03 cm\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_posteriori_files/figure-html/cell-3-output-2.png){width=1011 height=611}\n:::\n:::\n\n\nAgora, definimos o modelo Bayesiano COMPLETO no PyMC. Isso inclui as distribuições a priori (compartilhadas) e o likelihood, que conecta os parâmetros aos dados *observados*.\n\n::: {#f2eb30e4 .cell execution_count=3}\n``` {.python .cell-code}\n# Definindo o modelo Bayesiano COMPLETO no PyMC\nwith pm.Model() as normal_model:\n    # Priores (usamos as priores compartilhadas da parte anterior)\n    mu = pm.Normal(\"mu\", mu=175, sigma=10)       # Priori para a média\n    sigma = pm.HalfCauchy(\"sigma\", beta=0.1)    # Priori para o desvio padrão\n\n    # Likelihood: Distribuição dos dados OBSERVADOS, condicionada pelos parâmetros\n    # Aqui, informamos ao modelo quais dados foram observados usando o argumento 'observed'\n    likelihood = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=alturas_observadas)\n\n    # Inferência: Amostragem da distribuição a posteriori usando MCMC\n    # O PyMC usa o sampler NUTS (No-U-Turn Sampler) por padrão\n    # Ele explora o espaço de parâmetros para encontrar as regiões de alta probabilidade a posteriori\n    # draws: número de amostras a guardar por cadeia\n    # tune: número de passos de aquecimento (tuning) para o sampler convergir (descartados)\n    # cores: número de núcleos da CPU para rodar cadeias em paralelo (acelera)\n    # return_inferencedata=True: retorna um objeto ArviZ InferenceData, que é conveniente\n    trace = pm.sample(draws=2000, tune=1000, cores=4, return_inferencedata=True, random_seed=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu, sigma]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"1b49d1a4eda041e08cfc2b5cb55fd499\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 1 seconds.\n```\n:::\n:::\n\n\nO `pm.sample()` executa o algoritmo MCMC. Ele gera *amostras* da distribuição a posteriori conjunta de $\\mu$ e $\\sigma$. O resultado `trace` (um objeto InferenceData do ArviZ) contém essas amostras.\n\n**Inspeção e Interpretação da Posteriori:**\n\nAs amostras na `trace` representam nosso conhecimento atualizado sobre $\\mu$ e $\\sigma$ APÓS vermos os dados. Podemos resumir e visualizar essas amostras para entender a distribuição a posteriori.\n\n::: {#44ab0708 .cell execution_count=4}\n``` {.python .cell-code}\n# Resumo da distribuição a posteriori usando ArviZ\n# 'var_names' especifica quais variáveis queremos sumarizar\n# hdi_prob: probabilidade coberta pelo Intervalo de Maior Densidade (HDI - Highest Density Interval)\nsummary_stats = az.summary(trace, var_names=[\"mu\", \"sigma\"], hdi_prob=0.94, kind='stats')\n\nprint(\"Resumo das Estatísticas Posteriores:\")\nprint(summary_stats)\n\n# r_hat: Deve ser próximo de 1 (< 1.01 é bom), indica convergência entre as cadeias MCMC\n# ess_bulk / ess_tail: Effective Sample Size (tamanho efetivo da amostra), indica eficiência da amostragem\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResumo das Estatísticas Posteriores:\n          mean     sd   hdi_3%  hdi_97%\nmu     172.242  0.888  170.545  173.887\nsigma    9.094  0.656    7.872   10.313\n```\n:::\n:::\n\n\nO resumo mostra a média posterior, desvio padrão posterior e um Intervalo de Alta Densidade (HDI) de 94% para cada parâmetro. O HDI é um intervalo de credibilidade Bayesiano que contém 94% da massa de probabilidade posterior, incluindo os valores mais prováveis.\n\nVisualizações são essenciais para entender a posteriori:\n\n::: {#e8f89ebf .cell execution_count=5}\n``` {.python .cell-code}\n# Visualização da amostragem MCMC (Trace Plot) e da densidade a posteriori marginal\n# O trace plot (gráfico da esquerda) mostra a trajetória do sampler ao longo das iterações para cada cadeia.\n#   Idealmente, parece um \"ruído branco estacionário\", sem tendências ou padrões óbvios.\n# O histograma ou KDE (gráfico da direita) mostra a distribuição marginal a posteriori estimada de cada parâmetro.\naz.plot_trace(trace, var_names=[\"mu\", \"sigma\"])\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_148184/2558706149.py:6: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_posteriori_files/figure-html/cell-6-output-2.png){width=1187 height=388}\n:::\n:::\n\n\n::: {#297a30cd .cell execution_count=6}\n``` {.python .cell-code}\n# Visualização das densidades a posteriori marginais com média, mediana e HDI\n# Este plot foca na distribuição de probabilidade de cada parâmetro INDIVIDUALMENTE,\n# após levarmos em conta os dados e as priores.\naz.plot_posterior(trace, var_names=[\"mu\", \"sigma\"], hdi_prob=0.94)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_posteriori_files/figure-html/cell-7-output-1.png){width=1667 height=563}\n:::\n:::\n\n\n> **Discussão:**\n> *   Compare as distribuições a posteriori (visualizadas acima) com suas distribuições a priori iniciais (que você visualizou na Parte 2). Como os dados *atualizaram* suas crenças? Os centros das distribuições mudaram? Elas ficaram mais \"estreitas\" (menor incerteza)?\n> *   Qual é a média posterior estimada para $\\mu$? E para $\\sigma$? Como esses valores se comparam com a média (`171.66`) e o desvio padrão (`7.90`) calculados diretamente a partir dos dados observados (estimativas frequentistas)? Geralmente são próximos, mas não idênticos devido à influência (mesmo que pequena) das priores.\n> *   Interprete o intervalo HDI de 94% para $\\mu$ e $\\sigma$. Por exemplo, para $\\mu$, o intervalo é `[170.09, 173.23]`. Isso significa que, após observar os dados e considerando nossas priores, temos 94% de certeza (probabilidade Bayesiana) de que a verdadeira média populacional $\\mu$ da altura está entre 170.09 cm e 173.23 cm. Faça uma interpretação similar para $\\sigma$.\n\n**Checagem Posterior Preditiva:**\n\nAssim como fizemos a checagem priori preditiva, podemos fazer uma checagem *posterior* preditiva. Desta vez, geramos dados simulados a partir do modelo USANDO as amostras da *distribuição a posteriori* dos parâmetros ($\\mu$ e $\\sigma$). Cada conjunto de dados simulado usa um par $(\\mu, \\sigma)$ sorteado da posteriori. Isso nos diz que tipos de dados o modelo espera gerar agora que ele aprendeu com os dados observados. É uma ótima maneira de avaliar o **ajuste do modelo (model fit)**. Se os dados simulados a posteriori forem muito diferentes dos dados observados, o modelo pode não estar capturando bem as características dos dados reais.\n\n::: {#291bd830 .cell execution_count=7}\n``` {.python .cell-code}\n# Gerando amostras da POSTERIOR preditiva\n# Usamos o 'normal_model' (que contém o likelihood e as priores)\n# e o 'trace' (que contém as amostras da posteriori dos parâmetros)\nwith normal_model:\n    posterior_predictive_samples = pm.sample_posterior_predictive(trace, var_names=[\"likelihood\", \"mu\", \"sigma\"], random_seed=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling: [likelihood, mu, sigma]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"dbfdf629904c4fc781f70b478bda2787\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n:::\n\n\n::: {#98b39cab .cell execution_count=8}\n``` {.python .cell-code}\n# Visualizando a checagem posterior preditiva com ArviZ\n# Comparamos a distribuição dos dados observados (y) com as distribuições\n# de múltiplos conjuntos de dados simulados a partir da posteriori (y_pred).\n# 'kind='hist'' plota o histograma dos dados observados (azul escuro) e sobrepõe\n# histogramas de vários conjuntos de dados simulados da posteriori (azul claro).\n# Idealmente, o histograma observado deve se parecer com os simulados.\naz.plot_ppc(posterior_predictive_samples, num_pp_samples=100) # num_pp_samples controla quantos datasets simulados mostrar\nplt.title('Checagem Posterior Preditiva (PPC)', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Contagem (ou Densidade)', fontsize=12)\nplt.legend(fontsize=10)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_posteriori_files/figure-html/cell-9-output-1.png){width=731 height=491}\n:::\n:::\n\n\n> **Discussão:**\n> *   Observe a figura `plot_ppc` acima. Quão bem o histograma dos dados observados (geralmente em azul mais escuro ou preto) se alinha com os histogramas dos dados simulados a posteriori (linhas ou área em azul claro)? Eles cobrem o mesmo intervalo? Têm formas semelhantes?\n> *   O modelo Normal parece adequado para descrever a distribuição das alturas neste conjunto de dados? Se o histograma observado fosse muito diferente (ex: bimodal, muito assimétrico) dos simulados, isso indicaria que o modelo Normal talvez não seja a melhor escolha para estes dados específicos. Neste caso, o ajuste parece razoável.\n\n## Conclusão\n\nNesta semana, exploramos a Distribuição Normal e aprendemos como aplicá-la em um fluxo de trabalho de inferência Bayesiana usando o PyMC. Vimos como começar com intuições (priores), checar essas intuições (cheque priori preditivo), combinar priores com dados (inferência posterior via MCMC no PyMC) e avaliar o ajuste do modelo resultante (cheque posterior preditivo). Você agora tem as ferramentas básicas para modelar dados contínuos com incerteza usando a abordagem Bayesiana no Python!\n\n",
    "supporting": [
      "modelo_normal_bayesiano_posteriori_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"1b49d1a4eda041e08cfc2b5cb55fd499\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_340c969a44df41c9a04ebd2569c77661\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">                                                                                                                   \\n <span style=\\\"font-weight: bold\\\"> Progress                 </span> <span style=\\\"font-weight: bold\\\"> Draws </span> <span style=\\\"font-weight: bold\\\"> Divergences </span> <span style=\\\"font-weight: bold\\\"> Step size </span> <span style=\\\"font-weight: bold\\\"> Grad evals </span> <span style=\\\"font-weight: bold\\\"> Sampling Speed  </span> <span style=\\\"font-weight: bold\\\"> Elapsed </span> <span style=\\\"font-weight: bold\\\"> Remaining </span> \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.09        3            3012.97 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.40        3            3107.57 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.25        3            2806.64 draws/s   0:00:01   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.12        3            2293.54 draws/s   0:00:01   0:00:00    \\n                                                                                                                   \\n</pre>\\n\",\"text/plain\":\"                                                                                                                   \\n \\u001b[1m \\u001b[0m\\u001b[1mProgress                \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDraws\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDivergences\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mStep size\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mGrad evals\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mSampling Speed \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mElapsed\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mRemaining\\u001b[0m\\u001b[1m \\u001b[0m \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.09        3            3012.97 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.40        3            3107.57 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.25        3            2806.64 draws/s   0:00:01   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.12        3            2293.54 draws/s   0:00:01   0:00:00    \\n                                                                                                                   \\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"340c969a44df41c9a04ebd2569c77661\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"af032a58fbde43e483f273c8e2d8e23a\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"dbfdf629904c4fc781f70b478bda2787\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_af032a58fbde43e483f273c8e2d8e23a\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Sampling ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00 / 0:00:00\\n</pre>\\n\",\"text/plain\":\"Sampling ... \\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00 / 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}
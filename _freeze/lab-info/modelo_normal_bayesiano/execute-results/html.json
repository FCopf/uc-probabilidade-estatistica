{
  "hash": "d4b2d9e20d57e68f3844936af57a51c7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Distribuição Normal e Inferência Bayesiana\"\nsubtitle: \"Modelando Dados Contínuos no PyMC - distribições a priori\"\ndescription: \"Introdução à modelagem Bayesiana de dados contínuos, incluindo escolha de priores e checagens preditivas.\"\nformat: html\n---\n\n\n\n\nNesta semana, iremos a explorar a inferência Bayesiana, focando na modelagem de dados contínuos usando a Distribuição Normal. Nosso foco será desenvolver a intuição sobre como escolher distribuições a *priori* e como o PyMC nos ajuda a combinar essas crenças com dados observados para obter distribuições a *posteriori*. Para isdso usaremos um exemplo sobre a distribuição de altura em adultos.\n\n::: {.callout-important title=\"Objetivos de Aprendizagem\"}\nAo final desta aula, você deverá ser capaz de:\n\n*   Apresentar e entender a Distribuição Normal de forma intuitiva.\n*   Simular dados a partir de distribuições normais usando `scipy`.\n*   Utilizar seu conhecimento subjetivo para propor e visualizar distribuições a *priori* preditivas para parâmetros de um modelo Normal (como altura humana).\n*   Definir e ajustar um modelo Normal Bayesiano no PyMC.\n*   Extrair e interpretar as distribuições a *posteriori* dos parâmetros do modelo usando `arviz`.\n*   Gerar e avaliar checks preditivos a *posteriori* para verificar o ajuste do modelo.\n\n:::\n\n::: {#90fcb562 .cell execution_count=1}\n``` {.python .cell-code}\n# Importando bibliotecas necessárias\nimport pymc as pm\nimport arviz as az\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Configurações para plots\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (9, 6)\naz.style.use(\"arviz-darkgrid\")\n```\n:::\n\n\n## Explorando a Distribuição Normal\n\nA Distribuição Normal, frequentemente chamada de **curva de sino** ou **curva Gaussiana**, é central em estatística. Ela é caracterizada por dois parâmetros: a média ($\\mu$) e o desvio padrão ($\\sigma$). A média determina o centro da distribuição, enquanto o desvio padrão determina sua dispersão ou largura. Muitos fenômenos naturais podem ser adequadamente descritos por essa distribuição.\n\n**A ideia intuitiva:** Pense na altura de adultos. Há um valor central (a média) em torno do qual a maioria das alturas se agrupa. Há também uma variação: algumas pessoas são mais altas, outras mais baixas. O desvio padrão nos diz o quão espalhadas essas alturas tendem a ser em relação à média.\n\n### Curva de densidade de probabilidade\n\nGerando a Distribuição de Densidade Normal para diferentes valores de $\\mu$ e $\\sigma$.\n\n::: {#5cac1ee8 .cell execution_count=2}\n``` {.python .cell-code}\n# Parâmetros da distribuição\nmu_1 = 20\nsigma_1 = 3\n\nmu_2 = 20\nsigma_2 = 6\n\nmu_3 = 30\nsigma_3 = 5\n\n# Limites gráficos\nx_min = np.min(np.array([mu_1, mu_2, mu_3]) - 4*np.array([sigma_1, sigma_2, sigma_3]))\nx_max = np.max(np.array([mu_1, mu_2, mu_3]) + 4*np.array([sigma_1, sigma_2, sigma_3]))\nx = np.linspace(x_min, x_max, 1000) # Faixa de alturas para plotar\n\npdf_1 = stats.norm.pdf(x, loc=mu_1, scale=sigma_1)\npdf_2 = stats.norm.pdf(x, loc=mu_2, scale=sigma_2)\npdf_3 = stats.norm.pdf(x, loc=mu_3, scale=sigma_3)\n```\n:::\n\n\nVisualizando as distribuições de densidade de probabilidade\n\n::: {#cell-fig-normal-densities .cell execution_count=3}\n``` {.python .cell-code}\nplt.plot(x, pdf_1, label=f'$\\mu={mu_1}, \\sigma={sigma_1}$', color='b', lw=2)\nplt.plot(x, pdf_2, label=f'$\\mu={mu_2}, \\sigma={sigma_2}$', color='r', lw=2)\nplt.plot(x, pdf_3, label=f'$\\mu={mu_3}, \\sigma={sigma_3}$', color='g', lw=2)\nplt.xlabel('X', fontsize=12)\nplt.ylabel('Densidade de Probabilidade', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='-', alpha=0.7)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Desidades da distribuição normal para diferentes valores de μ e σ.](modelo_normal_bayesiano_files/figure-html/fig-normal-densities-output-1.png){#fig-normal-densities width=731 height=491}\n:::\n:::\n\n\n### Amostrando valores de distribuição normal {#sec-amostra-normal}\n\nNa @fig-normal-densities vemos as curvas teóricas de densidade da distribuiçao normal. Podemos também gerar *amostras* valores ao acaso destas distribuições para verificar como estas amostras se parecem. Isso simula o processo de **sortear** alturas de uma população que segue essa distribuição.\n\n::: {#c2eb4967 .cell execution_count=4}\n``` {.python .cell-code}\nmu = 20\nsigma = 4\nnum_amostras = 60\n```\n:::\n\n\nVerificando o histograma dos valores sorteados.\n\n::: {#cell-fig-normal-sampling .cell execution_count=5}\n``` {.python .cell-code}\namostras_altura = stats.norm.rvs(loc=mu, scale=sigma, size=num_amostras)\nx_dens = np.linspace(mu-4*sigma, mu+4*sigma, 500)\n\nplt.hist(amostras_altura, bins=30, density=True, alpha=0.8, color='lightblue', label='Amostras Geradas')\nsns.kdeplot(amostras_altura, color='blue', linewidth=2, label='Densidade Empírica')\nplt.plot(x_dens, stats.norm.pdf(x_dens, loc=mu, scale=sigma), color='red', linewidth=2.5, label='Densidade Teórica')\nplt.xlabel('X', fontsize=12)\nplt.ylabel('Densidade / Frequência Normalizada', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Histograma de amostras geradas a partir de uma distribuição normal com média $\\mu$ e desvio padrão $\\sigma$, acompanhado da densidade empírica estimada por kernel e da densidade teórica correspondente.](modelo_normal_bayesiano_files/figure-html/fig-normal-sampling-output-1.png){#fig-normal-sampling width=731 height=491}\n:::\n:::\n\n\n::: {.callout-tip title=\"Atividade em laboratório\"}\n\n- Rode este o trecho de código acima algumas vezes e observe como se dá a variação amostral.\n- Aumente e diminua o tamanho da amostras e verifique a variação entre as curvas enpíricas e a curva teórica.\n\n:::\n\n\n## Intuição Bayesiana\n\nEm inferência Bayesiana, começamos com crenças sobre os parâmetros (*a priori*) e as atualizamos com dados (*a posteriori*). Para a altura humana ($y$), podemos assumir que a distribuição normal é um bom modelo preditivo. \n\nDeste modo, escrevemos que:\n\n$$y \\sim \\mathcal{N}(\\mu, \\sigma)\n$$ {#eq-normal-alturas}\n\nEm seguida, precisamos sugerir uma dristribuição *a priori* para a média $\\mu$ e o desvio padrão $\\sigma$ que traduzam de forma adequada o que esperamos sobre a distribuição de altura em adultos. Sabemos por exemplo que a média da altura de adultos não é 50 cm nem 300 cm. Qual sua intuição sobre o desvio padrão?\n\n::: {.callout-tip title=\"Atividade em laboratório\"}\n\n1. Assumindo que a distribuição de alturas em adultos segue uma dsitribuição normal **proponha valores razoáveis** para a média ($\\mu$) e o desvio padrão ($\\sigma$).\n2. Para ajudar a decidir sobre o que seriam valores valores razoáveis, plote as curvas de densidade de probabilidade resultante de sua escolha e faça algumas simulações para verificar quais valores estremos sua escolha é capaz de gerar, utilizando os códigos da @sec-amostra-normal.\n\n:::\n\n### Checagem Priori Preditiva\n\nAssumindo que a altura de adultos segue uma distribuição (@eq-normal-alturas), vamos assumir que o parâmetro $\\mu$ segue também uma distribuição normal e que $\\sigma$ segue uma distribuição *log-normal*\n\nComo utilizamos estes pressupostos para escolher distribuição razoiáveis para $\\mu$ e $\\sigma$?\n\n**Priori para $\\mu$**\n\n::: {#76373234 .cell execution_count=6}\n``` {.python .cell-code}\nmean_prior_mu = 170 # INSIRA SUA ESCOLHA PARA A MÉDIA DA PRIORI DE mu\nsd_prior_mu = 2 # INSIRA SUA ESCOLHA PARA O DESVIO PADRÃO DA PRIORI DE mu\n\n# Gere sequancia de x e calcule a PDF\nxmean_prior = np.linspace(mean_prior_mu - 4*sd_prior_mu, mean_prior_mu + 4*sd_prior_mu, 1000)\npdf_mean_prior = stats.norm.pdf(x = xmean_prior, loc = mean_prior_mu, scale = sd_prior_mu)\n\n# Plote os resultados\nplt.plot(xmean_prior, pdf_mean_prior)\nplt.title(f'Priori para $\\mu$')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_files/figure-html/cell-7-output-1.png){width=731 height=491}\n:::\n:::\n\n\n**Priori para $\\sigma$**\n\n::: {#81edd4df .cell execution_count=7}\n``` {.python .cell-code}\nlmean_prior_sigma = 5 # INSIRA SUA ESCOLHA PARA A MÉDIA DA PRIORI DE sigma\nlsd_prior_sigma = 0.5 # INSIRA SUA ESCOLHA PARA O DESVIO PADRÃO DA PRIORI DE sigma\n\nxsd_prior = np.linspace(0.01, 20, 1000)\npdf_sd_prior = stats.lognorm.pdf(xsd_prior, s=lsd_prior_sigma, scale=lmean_prior_sigma)\n\nplt.plot(xsd_prior, pdf_sd_prior)\nplt.title(f'Priori para $\\sigma$')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_files/figure-html/cell-8-output-1.png){width=731 height=491}\n:::\n:::\n\n\n**Extraindo distribuição a priori preditiva de $y$ no PyMC**\n\n::: {#318a449d .cell execution_count=8}\n``` {.python .cell-code}\n# Definindo o modelo APENAS com as priores compartilhadas\nwith pm.Model() as prior_predictive_model:\n    \n    # Priori para a média\n    mu = pm.Normal(\"mu\", mu=175, sigma=10)\n\n    # Priori lognormal para o desvio padrão\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(5), sigma=0.5)\n\n    # Distribuição preditiva de y\n    y_pred = pm.Normal(\"y_pred\", mu=mu, sigma=sigma)\n\n    # Amostras da priori preditiva\n    prior_predictive_samples = pm.sample_prior_predictive(samples=1000)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling: [mu, sigma, y_pred]\n```\n:::\n:::\n\n\nAgora, vamos visualizar a distribuição dessas amostras preditivas a priori:\n\n::: {#cell-fig-predictive-y-prior .cell execution_count=9}\n``` {.python .cell-code}\ny_pred_prior = prior_predictive_samples.prior[\"y_pred\"].values.flatten()\n\nplt.figure(figsize=(10, 6))\nplt.hist(y_pred_prior, color='skyblue', edgecolor='black')\nplt.xlabel('Alturas priori simulada (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Range das alturas simuladas a priori](modelo_normal_bayesiano_files/figure-html/fig-predictive-y-prior-output-1.png){#fig-predictive-y-prior width=1011 height=611}\n:::\n:::\n\n\n::: {.callout-tip title=\"Discussão\"}\n\n Olhe para o histograma. As alturas simuladas parecem razoáveis para alturas de adultos? A distribuição faz sentido dada a sua intuição? Se sim, suas priores iniciais eram sensatas. Se não, é importante considerar um ajuste de suas priores (ex: tornar a priori de $\\sigma$ mais restrita se a dispersão for muito grande, ou ajustar a localização/escala da priori de $\\mu$).\n\n:::\n\n**Checagem priori preditiva com PyMC**\n\nPodemos chegar não somente a distribuição preditiva de $y$, mas também dos parâmetros $\\mu$ e $\\sigma$ usando o PyMC.\nAlém disso, poderíamos testar outras distribuições a priori para algum dos parâmetros, por exemplo sigma. Teste cada uma destas e verifique os efeitos sobre as distribuições preditivas.\n\n::: {#a0cc4c03 .cell execution_count=10}\n``` {.python .cell-code}\n# Definindo o modelo APENAS com as priores compartilhadas\nwith pm.Model() as prior_predictive_model:\n    \n    # Priori para a média\n    mu = pm.Normal(\"mu\", mu=175, sigma=10)\n\n    # Escolha uma das prioris para sigma:\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(0.08), sigma=0.5)\n    # sigma = pm.InverseGamma(\"sigma\", alpha=8, beta=0.9)\n    # sigma = pm.HalfNormal(\"sigma\", sigma=0.1)\n    # sigma = pm.HalfCauchy(\"sigma\", beta=0.1)\n    # sigma = pm.Exponential(\"sigma\", lam=20)\n    # sigma = pm.TruncatedNormal(\"sigma\", mu=0.08, sigma=0.02, lower=0)\n    # sigma = pm.Uniform(\"sigma\", lower=0, upper=1)\n\n    # Distribuição preditiva de y\n    y_pred = pm.Normal(\"y_pred\", mu=mu, sigma=sigma)\n\n    # Amostras da priori preditiva\n    prior_predictive_samples = pm.sample_prior_predictive(samples=1000)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling: [mu, sigma, y_pred]\n```\n:::\n:::\n\n\n::: {#cell-fig-predictive-priors .cell execution_count=11}\n``` {.python .cell-code}\nmu_pred_prior = prior_predictive_samples.prior[\"mu\"].values.flatten()\nsigma_pred_prior = prior_predictive_samples.prior[\"sigma\"].values.flatten()\ny_pred_prior = prior_predictive_samples.prior[\"y_pred\"].values.flatten()\n\nfig, axes = plt.subplots(1, 3, figsize=(9, 3))\n\naxes[0].hist(mu_pred_prior, bins=30, color='skyblue', edgecolor='black')\naxes[0].set_xlabel(\"μ\")\naxes[0].set_ylabel(\"Frequência\")\n\naxes[1].hist(sigma_pred_prior, bins=30, color='lightgreen', edgecolor='black')\naxes[1].set_xlabel(\"σ\")\naxes[1].set_ylabel(\"Frequência\")\n\naxes[2].hist(y_pred_prior, bins=30, color='salmon', edgecolor='black')\naxes[2].set_xlabel(\"alturas (y)\")\naxes[2].set_ylabel(\"Frequência\")\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_147230/1739690728.py:19: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Distribuiões a priori da média, desvio padrão e y predito](modelo_normal_bayesiano_files/figure-html/fig-predictive-priors-output-2.png){#fig-predictive-priors width=890 height=292}\n:::\n:::\n\n\n## Inferência Posterior e Posterior Predictive Checks\n\nAgora é hora de incorporar dados reais. Vamos usar um conjunto de dados de exemplo (simulado para este notebook, mas pode ser substituído por dados reais da sua turma ou de outra fonte) e realizar a inferência Bayesiana completa.\n\n::: {#f9feae96 .cell execution_count=12}\n``` {.python .cell-code}\n# Gerando um conjunto de dados de exemplo (substituir por dados reais se disponíveis)\nnp.random.seed(123) # Para reprodutibilidade\nmedia_real_simulada = 172\ndp_real_simulado = 8\nn_observacoes = 100\nalturas_observadas = stats.norm.rvs(loc=media_real_simulada, scale=dp_real_simulado, size=n_observacoes)\n\nprint(f\"Dados observados (primeiros 10): {alturas_observadas[:10]}\")\nprint(f\"\\nMédia amostral: {np.mean(alturas_observadas):.2f} cm\")\nprint(f\"Desvio padrão amostral: {np.std(alturas_observadas):.2f} cm\")\n\nplt.figure(figsize=(10, 6))\nplt.hist(alturas_observadas, bins=15, density=True, alpha=0.8, color='gray', label='Dados Observados')\nplt.title(f'Histograma das {n_observacoes} Alturas Observadas', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.legend()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDados observados (primeiros 10): [163.31495517 179.97876357 174.26382798 159.94964229 167.37119798\n 185.2114923  152.58656605 168.56869897 182.12749007 165.06607678]\n\nMédia amostral: 172.22 cm\nDesvio padrão amostral: 9.03 cm\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_files/figure-html/cell-13-output-2.png){width=1011 height=611}\n:::\n:::\n\n\nAgora, definimos o modelo Bayesiano COMPLETO no PyMC. Isso inclui as distribuições a priori (compartilhadas) e o likelihood, que conecta os parâmetros aos dados *observados*.\n\n::: {#38b1f532 .cell execution_count=13}\n``` {.python .cell-code}\n# Definindo o modelo Bayesiano COMPLETO no PyMC\nwith pm.Model() as normal_model:\n    # Priores (usamos as priores compartilhadas da parte anterior)\n    mu = pm.Normal(\"mu\", mu=175, sigma=10)       # Priori para a média\n    sigma = pm.HalfCauchy(\"sigma\", beta=0.1)    # Priori para o desvio padrão\n\n    # Likelihood: Distribuição dos dados OBSERVADOS, condicionada pelos parâmetros\n    # Aqui, informamos ao modelo quais dados foram observados usando o argumento 'observed'\n    likelihood = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=alturas_observadas)\n\n    # Inferência: Amostragem da distribuição a posteriori usando MCMC\n    # O PyMC usa o sampler NUTS (No-U-Turn Sampler) por padrão\n    # Ele explora o espaço de parâmetros para encontrar as regiões de alta probabilidade a posteriori\n    # draws: número de amostras a guardar por cadeia\n    # tune: número de passos de aquecimento (tuning) para o sampler convergir (descartados)\n    # cores: número de núcleos da CPU para rodar cadeias em paralelo (acelera)\n    # return_inferencedata=True: retorna um objeto ArviZ InferenceData, que é conveniente\n    trace = pm.sample(draws=2000, tune=1000, cores=4, return_inferencedata=True, random_seed=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu, sigma]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"0b722a615d384ac28abb2b129e62ecc3\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 1 seconds.\n```\n:::\n:::\n\n\nO `pm.sample()` executa o algoritmo MCMC. Ele gera *amostras* da distribuição a posteriori conjunta de $\\mu$ e $\\sigma$. O resultado `trace` (um objeto InferenceData do ArviZ) contém essas amostras.\n\n**Inspeção e Interpretação da Posteriori:**\n\nAs amostras na `trace` representam nosso conhecimento atualizado sobre $\\mu$ e $\\sigma$ APÓS vermos os dados. Podemos resumir e visualizar essas amostras para entender a distribuição a posteriori.\n\n::: {#a79ab9f9 .cell execution_count=14}\n``` {.python .cell-code}\n# Resumo da distribuição a posteriori usando ArviZ\n# 'var_names' especifica quais variáveis queremos sumarizar\n# hdi_prob: probabilidade coberta pelo Intervalo de Maior Densidade (HDI - Highest Density Interval)\nsummary_stats = az.summary(trace, var_names=[\"mu\", \"sigma\"], hdi_prob=0.94, kind='stats')\n\nprint(\"Resumo das Estatísticas Posteriores:\")\nprint(summary_stats)\n\n# r_hat: Deve ser próximo de 1 (< 1.01 é bom), indica convergência entre as cadeias MCMC\n# ess_bulk / ess_tail: Effective Sample Size (tamanho efetivo da amostra), indica eficiência da amostragem\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResumo das Estatísticas Posteriores:\n          mean     sd   hdi_3%  hdi_97%\nmu     172.242  0.888  170.545  173.887\nsigma    9.094  0.656    7.872   10.313\n```\n:::\n:::\n\n\nO resumo mostra a média posterior, desvio padrão posterior e um Intervalo de Alta Densidade (HDI) de 94% para cada parâmetro. O HDI é um intervalo de credibilidade Bayesiano que contém 94% da massa de probabilidade posterior, incluindo os valores mais prováveis.\n\nVisualizações são essenciais para entender a posteriori:\n\n::: {#6eccae7c .cell execution_count=15}\n``` {.python .cell-code}\n# Visualização da amostragem MCMC (Trace Plot) e da densidade a posteriori marginal\n# O trace plot (gráfico da esquerda) mostra a trajetória do sampler ao longo das iterações para cada cadeia.\n#   Idealmente, parece um \"ruído branco estacionário\", sem tendências ou padrões óbvios.\n# O histograma ou KDE (gráfico da direita) mostra a distribuição marginal a posteriori estimada de cada parâmetro.\naz.plot_trace(trace, var_names=[\"mu\", \"sigma\"])\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_147230/2558706149.py:6: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_files/figure-html/cell-16-output-2.png){width=1187 height=388}\n:::\n:::\n\n\n::: {#42c46d90 .cell execution_count=16}\n``` {.python .cell-code}\n# Visualização das densidades a posteriori marginais com média, mediana e HDI\n# Este plot foca na distribuição de probabilidade de cada parâmetro INDIVIDUALMENTE,\n# após levarmos em conta os dados e as priores.\naz.plot_posterior(trace, var_names=[\"mu\", \"sigma\"], hdi_prob=0.94)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_files/figure-html/cell-17-output-1.png){width=1667 height=563}\n:::\n:::\n\n\n> **Discussão:**\n> *   Compare as distribuições a posteriori (visualizadas acima) com suas distribuições a priori iniciais (que você visualizou na Parte 2). Como os dados *atualizaram* suas crenças? Os centros das distribuições mudaram? Elas ficaram mais \"estreitas\" (menor incerteza)?\n> *   Qual é a média posterior estimada para $\\mu$? E para $\\sigma$? Como esses valores se comparam com a média (`171.66`) e o desvio padrão (`7.90`) calculados diretamente a partir dos dados observados (estimativas frequentistas)? Geralmente são próximos, mas não idênticos devido à influência (mesmo que pequena) das priores.\n> *   Interprete o intervalo HDI de 94% para $\\mu$ e $\\sigma$. Por exemplo, para $\\mu$, o intervalo é `[170.09, 173.23]`. Isso significa que, após observar os dados e considerando nossas priores, temos 94% de certeza (probabilidade Bayesiana) de que a verdadeira média populacional $\\mu$ da altura está entre 170.09 cm e 173.23 cm. Faça uma interpretação similar para $\\sigma$.\n\n**Checagem Posterior Preditiva:**\n\nAssim como fizemos a checagem priori preditiva, podemos fazer uma checagem *posterior* preditiva. Desta vez, geramos dados simulados a partir do modelo USANDO as amostras da *distribuição a posteriori* dos parâmetros ($\\mu$ e $\\sigma$). Cada conjunto de dados simulado usa um par $(\\mu, \\sigma)$ sorteado da posteriori. Isso nos diz que tipos de dados o modelo espera gerar agora que ele aprendeu com os dados observados. É uma ótima maneira de avaliar o **ajuste do modelo (model fit)**. Se os dados simulados a posteriori forem muito diferentes dos dados observados, o modelo pode não estar capturando bem as características dos dados reais.\n\n::: {#645a69bc .cell execution_count=17}\n``` {.python .cell-code}\n# Gerando amostras da POSTERIOR preditiva\n# Usamos o 'normal_model' (que contém o likelihood e as priores)\n# e o 'trace' (que contém as amostras da posteriori dos parâmetros)\nwith normal_model:\n    posterior_predictive_samples = pm.sample_posterior_predictive(trace, var_names=[\"likelihood\", \"mu\", \"sigma\"], random_seed=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling: [likelihood, mu, sigma]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"2283b63ff835401884ea45389af761bb\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n:::\n\n\n::: {#8ad5b7a8 .cell execution_count=18}\n``` {.python .cell-code}\n# Visualizando a checagem posterior preditiva com ArviZ\n# Comparamos a distribuição dos dados observados (y) com as distribuições\n# de múltiplos conjuntos de dados simulados a partir da posteriori (y_pred).\n# 'kind='hist'' plota o histograma dos dados observados (azul escuro) e sobrepõe\n# histogramas de vários conjuntos de dados simulados da posteriori (azul claro).\n# Idealmente, o histograma observado deve se parecer com os simulados.\naz.plot_ppc(posterior_predictive_samples, num_pp_samples=100) # num_pp_samples controla quantos datasets simulados mostrar\nplt.title('Checagem Posterior Preditiva (PPC)', fontsize=14)\nplt.xlabel('Altura (cm)', fontsize=12)\nplt.ylabel('Contagem (ou Densidade)', fontsize=12)\nplt.legend(fontsize=10)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](modelo_normal_bayesiano_files/figure-html/cell-19-output-1.png){width=731 height=491}\n:::\n:::\n\n\n> **Discussão:**\n> *   Observe a figura `plot_ppc` acima. Quão bem o histograma dos dados observados (geralmente em azul mais escuro ou preto) se alinha com os histogramas dos dados simulados a posteriori (linhas ou área em azul claro)? Eles cobrem o mesmo intervalo? Têm formas semelhantes?\n> *   O modelo Normal parece adequado para descrever a distribuição das alturas neste conjunto de dados? Se o histograma observado fosse muito diferente (ex: bimodal, muito assimétrico) dos simulados, isso indicaria que o modelo Normal talvez não seja a melhor escolha para estes dados específicos. Neste caso, o ajuste parece razoável.\n\n## Conclusão\n\nNesta semana, exploramos a Distribuição Normal e aprendemos como aplicá-la em um fluxo de trabalho de inferência Bayesiana usando o PyMC. Vimos como começar com intuições (priores), checar essas intuições (cheque priori preditivo), combinar priores com dados (inferência posterior via MCMC no PyMC) e avaliar o ajuste do modelo resultante (cheque posterior preditivo). Você agora tem as ferramentas básicas para modelar dados contínuos com incerteza usando a abordagem Bayesiana no Python!\n\n",
    "supporting": [
      "modelo_normal_bayesiano_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"0b722a615d384ac28abb2b129e62ecc3\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_fa4c4830d43c4a329129dbeeef9cdcf0\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">                                                                                                                   \\n <span style=\\\"font-weight: bold\\\"> Progress                 </span> <span style=\\\"font-weight: bold\\\"> Draws </span> <span style=\\\"font-weight: bold\\\"> Divergences </span> <span style=\\\"font-weight: bold\\\"> Step size </span> <span style=\\\"font-weight: bold\\\"> Grad evals </span> <span style=\\\"font-weight: bold\\\"> Sampling Speed  </span> <span style=\\\"font-weight: bold\\\"> Elapsed </span> <span style=\\\"font-weight: bold\\\"> Remaining </span> \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.09        3            3192.20 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.40        3            3121.79 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.25        3            2881.30 draws/s   0:00:01   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.12        3            2407.36 draws/s   0:00:01   0:00:00    \\n                                                                                                                   \\n</pre>\\n\",\"text/plain\":\"                                                                                                                   \\n \\u001b[1m \\u001b[0m\\u001b[1mProgress                \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDraws\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDivergences\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mStep size\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mGrad evals\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mSampling Speed \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mElapsed\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mRemaining\\u001b[0m\\u001b[1m \\u001b[0m \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.09        3            3192.20 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.40        3            3121.79 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.25        3            2881.30 draws/s   0:00:01   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   3000    0             1.12        3            2407.36 draws/s   0:00:01   0:00:00    \\n                                                                                                                   \\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"2283b63ff835401884ea45389af761bb\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_2890dd91c40a4b3cb3a85398b8b96f95\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Sampling ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00 / 0:00:00\\n</pre>\\n\",\"text/plain\":\"Sampling ... \\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00 / 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"2890dd91c40a4b3cb3a85398b8b96f95\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"fa4c4830d43c4a329129dbeeef9cdcf0\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}